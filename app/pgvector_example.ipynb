{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# pgVector and LangChain Example Notebook\n",
        "\n",
        "This notebook demonstrates how to store documents in a vector database and perform similarity searches using pgVector and LangChain.\n",
        "\n",
        "## Features:\n",
        "- 🔄 **Random Vector Embeddings**: No OpenAI API key required\n",
        "- 📚 **Document Storage**: Store sample documents with metadata\n",
        "- 🔍 **Similarity Search**: Find similar documents\n",
        "- 🏷️ **Metadata Filtering**: Filter results by metadata\n",
        "- 🎯 **Direct Vector Search**: Search using vector embeddings directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/jyje/Library/CloudStorage/OneDrive-개인/Codes/Profile/jyje/Repos/pilot-langchain-pgvector/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Import required libraries and existing functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "\n",
        "# Import from our existing modules\n",
        "from vector_example import RandomEmbeddings, create_sample_documents\n",
        "from config import DATABASE_URL, VECTOR_DIMENSION, COLLECTION_NAME\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain_community.vectorstores import PGVector\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"📦 All libraries imported successfully!\")\n",
        "print(f\"🔗 Database URL: {DATABASE_URL}\")\n",
        "print(f\"📏 Vector Dimension: {VECTOR_DIMENSION}\")\n",
        "print(f\"📂 Collection Name: {COLLECTION_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# pgVector and LangChain Example Notebook\n",
        "\n",
        "This notebook demonstrates how to store documents in a vector database and perform similarity searches using pgVector and LangChain.\n",
        "\n",
        "## Features:\n",
        "- 🔄 **Random Vector Embeddings**: No OpenAI API key required\n",
        "- 📚 **Document Storage**: Store sample documents with metadata  \n",
        "- 🔍 **Similarity Search**: Find similar documents\n",
        "- 🏷️ **Metadata Filtering**: Filter results by metadata\n",
        "- 🎯 **Direct Vector Search**: Search using vector embeddings directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries and existing functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "\n",
        "# Import from our existing modules\n",
        "from vector_example import RandomEmbeddings, create_sample_documents\n",
        "from config import DATABASE_URL, VECTOR_DIMENSION, COLLECTION_NAME\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain_community.vectorstores import PGVector\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"📦 All libraries imported successfully!\")\n",
        "print(f\"🔗 Database URL: {DATABASE_URL}\")\n",
        "print(f\"📏 Vector Dimension: {VECTOR_DIMENSION}\")\n",
        "print(f\"📂 Collection Name: {COLLECTION_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 📚 Data Generation\n",
        "\n",
        "Let's generate sample documents using the existing `create_sample_documents()` function and explore the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample documents using existing function\n",
        "sample_documents = create_sample_documents()\n",
        "\n",
        "print(f\"📊 Generated {len(sample_documents)} sample documents\\n\")\n",
        "\n",
        "# Display the documents in a nice format\n",
        "for i, doc in enumerate(sample_documents, 1):\n",
        "    print(f\"🔹 Document {i}:\")\n",
        "    print(f\"   Content: {doc.page_content}\")\n",
        "    print(f\"   Metadata: {doc.metadata}\")\n",
        "    print()\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "data = []\n",
        "for doc in sample_documents:\n",
        "    data.append({\n",
        "        'id': doc.metadata['id'],\n",
        "        'content': doc.page_content,\n",
        "        'category': doc.metadata['category'],\n",
        "        'source': doc.metadata['source']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"📋 Documents as DataFrame:\")\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 🔧 Vector Store Initialization\n",
        "\n",
        "Initialize the embedding model and pgVector store for data storage and retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize embedding model (random vectors for demonstration)\n",
        "embeddings = RandomEmbeddings(dimension=VECTOR_DIMENSION)\n",
        "print(f\"🧮 Initialized RandomEmbeddings with {VECTOR_DIMENSION} dimensions\")\n",
        "\n",
        "# Test the embedding model\n",
        "test_vector = embeddings.embed_query(\"Test query\")\n",
        "print(f\"🔍 Sample vector shape: {len(test_vector)}\")\n",
        "print(f\"🔢 Sample vector (first 5 elements): {test_vector[:5]}\")\n",
        "\n",
        "# Initialize PGVector store\n",
        "try:\n",
        "    vector_store = PGVector(\n",
        "        connection_string=DATABASE_URL,\n",
        "        embedding_function=embeddings,\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        distance_strategy=\"cosine\"\n",
        "    )\n",
        "    print(\"✅ pgVector store initialized successfully!\")\n",
        "    print(f\"📊 Using cosine distance for similarity search\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to initialize pgVector store: {e}\")\n",
        "    print(\"🔧 Make sure Docker containers are running: cd docker && docker-compose up -d\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 💾 Data Storage (Training Phase)\n",
        "\n",
        "Store the generated documents in the pgVector database. This is equivalent to the \"training\" phase where we build our vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store documents in the vector database\n",
        "print(\"💾 Storing documents in pgVector database...\")\n",
        "\n",
        "try:\n",
        "    vector_store.add_documents(sample_documents)\n",
        "    print(f\"✅ Successfully stored {len(sample_documents)} documents!\")\n",
        "    \n",
        "    # Verify storage by checking if we can retrieve any documents\n",
        "    print(\"\\n🔍 Verifying data storage...\")\n",
        "    \n",
        "    # Try a simple search to verify\n",
        "    test_results = vector_store.similarity_search(\"technology\", k=1)\n",
        "    if test_results:\n",
        "        print(f\"✅ Verification successful! Found {len(test_results)} document(s)\")\n",
        "        print(f\"📄 Sample document: {test_results[0].page_content[:50]}...\")\n",
        "    else:\n",
        "        print(\"⚠️ No documents found in verification search\")\n",
        "    \n",
        "    print(f\"\\n📊 Database now contains vector embeddings for all documents\")\n",
        "    print(f\"🔢 Each document is represented as a {VECTOR_DIMENSION}-dimensional vector\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to store documents: {e}\")\n",
        "    print(\"🔧 Check if the database connection is working properly\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. 🔍 Basic Similarity Search\n",
        "\n",
        "Perform similarity searches using different query texts to find the most relevant documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define search queries for testing\n",
        "search_queries = [\n",
        "    \"Tell me about artificial intelligence and machine learning\",\n",
        "    \"What are data analysis technologies?\", \n",
        "    \"Explain cloud and distributed systems\",\n",
        "    \"How does blockchain technology work?\",\n",
        "    \"What is computer vision and image processing?\"\n",
        "]\n",
        "\n",
        "print(\"🔍 Performing similarity searches...\\n\")\n",
        "\n",
        "# Perform searches and display results\n",
        "for i, query in enumerate(search_queries, 1):\n",
        "    print(f\"🔸 Search {i}: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Basic similarity search\n",
        "        similar_docs = vector_store.similarity_search(query, k=3)\n",
        "        \n",
        "        if similar_docs:\n",
        "            print(\"📋 Top 3 similar documents:\")\n",
        "            for j, doc in enumerate(similar_docs, 1):\n",
        "                print(f\"   {j}. {doc.page_content}\")\n",
        "                print(f\"      📂 Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "                print(f\"      🆔 ID: {doc.metadata.get('id', 'N/A')}\")\n",
        "            \n",
        "            # Search with similarity scores\n",
        "            similar_docs_with_scores = vector_store.similarity_search_with_score(query, k=3)\n",
        "            print(\"\\n📊 Similarity scores:\")\n",
        "            for j, (doc, score) in enumerate(similar_docs_with_scores, 1):\n",
        "                print(f\"   {j}. Score: {score:.4f}\")\n",
        "        else:\n",
        "            print(\"❌ No similar documents found\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Search failed: {e}\")\n",
        "    \n",
        "    print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 🏷️ Metadata Filtering Search\n",
        "\n",
        "Demonstrate how to filter search results based on metadata criteria.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metadata filtering search examples\n",
        "print(\"🏷️ Performing metadata filtering searches...\\n\")\n",
        "\n",
        "# Example 1: Filter by category\n",
        "try:\n",
        "    print(\"🔹 Filter 1: Only 'technology' category documents\")\n",
        "    filtered_docs = vector_store.similarity_search(\n",
        "        query=\"Tell me about technology\",\n",
        "        k=5,\n",
        "        filter={\"category\": \"technology\"}\n",
        "    )\n",
        "    \n",
        "    if filtered_docs:\n",
        "        print(f\"📋 Found {len(filtered_docs)} documents in 'technology' category:\")\n",
        "        for i, doc in enumerate(filtered_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      📂 Category: {doc.metadata['category']}\")\n",
        "            print(f\"      🆔 ID: {doc.metadata['id']}\")\n",
        "    else:\n",
        "        print(\"❌ No documents found with specified filter\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Filtered search failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Example 2: Filter by source\n",
        "try:\n",
        "    print(\"🔹 Filter 2: Only 'sample_data' source documents\")\n",
        "    filtered_docs = vector_store.similarity_search(\n",
        "        query=\"data processing\",\n",
        "        k=3,\n",
        "        filter={\"source\": \"sample_data\"}\n",
        "    )\n",
        "    \n",
        "    if filtered_docs:\n",
        "        print(f\"📋 Found {len(filtered_docs)} documents from 'sample_data' source:\")\n",
        "        for i, doc in enumerate(filtered_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      🔗 Source: {doc.metadata['source']}\")\n",
        "    else:\n",
        "        print(\"❌ No documents found with specified filter\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Filtered search failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Example 3: Search without filter for comparison\n",
        "try:\n",
        "    print(\"🔹 Comparison: Search without any filters\")\n",
        "    all_docs = vector_store.similarity_search(\n",
        "        query=\"technology and data\",\n",
        "        k=3\n",
        "    )\n",
        "    \n",
        "    if all_docs:\n",
        "        print(f\"📋 Found {len(all_docs)} documents (no filter):\")\n",
        "        for i, doc in enumerate(all_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      📂 Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "            print(f\"      🔗 Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"❌ No documents found\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Search failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 🎯 Direct Vector Search\n",
        "\n",
        "Demonstrate searching using vector embeddings directly, without query text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Direct vector search examples\n",
        "print(\"🎯 Performing direct vector searches...\\n\")\n",
        "\n",
        "# Generate multiple random vectors for testing\n",
        "num_searches = 3\n",
        "for i in range(num_searches):\n",
        "    print(f\"🔸 Vector Search {i+1}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        # Generate a random vector\n",
        "        random_vector = embeddings.embed_query(f\"random search {i+1}\")\n",
        "        \n",
        "        print(f\"🧮 Generated random vector with {len(random_vector)} dimensions\")\n",
        "        print(f\"🔢 Vector sample (first 5 elements): {random_vector[:5]}\")\n",
        "        \n",
        "        # Search using the random vector\n",
        "        similar_docs = vector_store.similarity_search_by_vector(\n",
        "            embedding=random_vector,\n",
        "            k=3\n",
        "        )\n",
        "        \n",
        "        if similar_docs:\n",
        "            print(f\"\\n📋 Found {len(similar_docs)} similar documents:\")\n",
        "            for j, doc in enumerate(similar_docs, 1):\n",
        "                print(f\"   {j}. {doc.page_content}\")\n",
        "                print(f\"      📂 Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "                print(f\"      🆔 ID: {doc.metadata.get('id', 'N/A')}\")\n",
        "        else:\n",
        "            print(\"❌ No similar documents found\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Vector search failed: {e}\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Compare vector search with text search\n",
        "print(\"🔀 Comparison: Vector vs Text Search\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    # Generate a vector for a specific query\n",
        "    query_text = \"machine learning and AI\"\n",
        "    query_vector = embeddings.embed_query(query_text)\n",
        "    \n",
        "    # Text-based search\n",
        "    text_results = vector_store.similarity_search(query_text, k=2)\n",
        "    \n",
        "    # Vector-based search using the same vector\n",
        "    vector_results = vector_store.similarity_search_by_vector(query_vector, k=2)\n",
        "    \n",
        "    print(f\"📝 Text search for: '{query_text}'\")\n",
        "    if text_results:\n",
        "        for i, doc in enumerate(text_results, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "    \n",
        "    print(f\"\\n🧮 Vector search using embedding of: '{query_text}'\")\n",
        "    if vector_results:\n",
        "        for i, doc in enumerate(vector_results, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "    \n",
        "    # Note about randomness\n",
        "    print(f\"\\n💡 Note: Since we're using random embeddings, results may vary between runs\")\n",
        "    print(f\"   In production, you'd use consistent embeddings like OpenAI's text-embedding-ada-002\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Comparison search failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. 📊 Search Results Analysis\n",
        "\n",
        "Let's analyze and visualize the search results to better understand the vector database performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze search performance and results\n",
        "print(\"📊 Analyzing search results and database performance...\\n\")\n",
        "\n",
        "# Collect search statistics\n",
        "search_stats = {\n",
        "    'total_documents': len(sample_documents),\n",
        "    'search_queries_tested': len(search_queries),\n",
        "    'categories': set(),\n",
        "    'sources': set(),\n",
        "    'similarity_scores': []\n",
        "}\n",
        "\n",
        "# Analyze stored documents\n",
        "for doc in sample_documents:\n",
        "    search_stats['categories'].add(doc.metadata.get('category', 'Unknown'))\n",
        "    search_stats['sources'].add(doc.metadata.get('source', 'Unknown'))\n",
        "\n",
        "# Perform a comprehensive search analysis\n",
        "comprehensive_query = \"technology data science machine learning\"\n",
        "print(f\"🔍 Comprehensive analysis with query: '{comprehensive_query}'\")\n",
        "\n",
        "try:\n",
        "    # Get all results with scores\n",
        "    all_results = vector_store.similarity_search_with_score(\n",
        "        comprehensive_query, \n",
        "        k=len(sample_documents)  # Get all documents\n",
        "    )\n",
        "    \n",
        "    if all_results:\n",
        "        # Extract scores for analysis\n",
        "        scores = [score for _, score in all_results]\n",
        "        search_stats['similarity_scores'] = scores\n",
        "        \n",
        "        # Create results DataFrame\n",
        "        results_data = []\n",
        "        for i, (doc, score) in enumerate(all_results, 1):\n",
        "            results_data.append({\n",
        "                'rank': i,\n",
        "                'content': doc.page_content[:50] + \"...\",\n",
        "                'category': doc.metadata.get('category', 'N/A'),\n",
        "                'source': doc.metadata.get('source', 'N/A'),\n",
        "                'similarity_score': round(score, 4),\n",
        "                'document_id': doc.metadata.get('id', 'N/A')\n",
        "            })\n",
        "        \n",
        "        results_df = pd.DataFrame(results_data)\n",
        "        print(\"\\n📋 Complete Search Results:\")\n",
        "        display(results_df)\n",
        "        \n",
        "        # Statistics summary\n",
        "        print(f\"\\n📈 Search Statistics Summary:\")\n",
        "        print(f\"   📚 Total documents in database: {search_stats['total_documents']}\")\n",
        "        print(f\"   🔍 Search queries tested: {search_stats['search_queries_tested']}\")\n",
        "        print(f\"   📂 Categories found: {', '.join(search_stats['categories'])}\")\n",
        "        print(f\"   🔗 Sources found: {', '.join(search_stats['sources'])}\")\n",
        "        print(f\"   📊 Similarity score range: {min(scores):.4f} - {max(scores):.4f}\")\n",
        "        print(f\"   📊 Average similarity score: {np.mean(scores):.4f}\")\n",
        "        print(f\"   📊 Similarity score std dev: {np.std(scores):.4f}\")\n",
        "        \n",
        "        # Top and bottom results\n",
        "        print(f\"\\n🏆 Most similar document:\")\n",
        "        print(f\"   Content: {all_results[0][0].page_content}\")\n",
        "        print(f\"   Score: {all_results[0][1]:.4f}\")\n",
        "        \n",
        "        print(f\"\\n🔻 Least similar document:\")\n",
        "        print(f\"   Content: {all_results[-1][0].page_content}\")\n",
        "        print(f\"   Score: {all_results[-1][1]:.4f}\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ No results found for comprehensive analysis\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Analysis failed: {e}\")\n",
        "\n",
        "# Performance note\n",
        "print(f\"\\n💡 Performance Notes:\")\n",
        "print(f\"   🔄 Random embeddings provide consistent vector operations\")\n",
        "print(f\"   ⚡ Search speed depends on database size and indexing\")\n",
        "print(f\"   🎯 In production, use semantic embeddings (OpenAI, Sentence Transformers, etc.)\")\n",
        "print(f\"   📈 Vector similarity scores closer to 0 indicate higher similarity (cosine distance)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. 🎉 Summary and Next Steps\n",
        "\n",
        "This notebook demonstrated the complete workflow of using pgVector with LangChain for vector-based document storage and retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of what we accomplished\n",
        "print(\"🎉 Notebook Execution Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "summary_points = [\n",
        "    \"✅ Successfully imported functions from vector_example.py\",\n",
        "    \"✅ Generated sample documents with metadata\",\n",
        "    \"✅ Initialized RandomEmbeddings (no OpenAI API required)\",\n",
        "    \"✅ Connected to pgVector database\",\n",
        "    \"✅ Stored documents in vector database (training phase)\",\n",
        "    \"✅ Performed similarity searches with various queries\",\n",
        "    \"✅ Demonstrated metadata filtering capabilities\",\n",
        "    \"✅ Executed direct vector searches\",\n",
        "    \"✅ Analyzed search results and performance statistics\"\n",
        "]\n",
        "\n",
        "for point in summary_points:\n",
        "    print(f\"  {point}\")\n",
        "\n",
        "print(f\"\\n📊 Final Statistics:\")\n",
        "print(f\"  📚 Documents stored: {len(sample_documents)}\")\n",
        "print(f\"  🔍 Search methods tested: Text search, Filtered search, Vector search\")\n",
        "print(f\"  📏 Vector dimensions: {VECTOR_DIMENSION}\")\n",
        "print(f\"  🎯 Distance metric: Cosine similarity\")\n",
        "\n",
        "print(f\"\\n🚀 Next Steps for Production:\")\n",
        "next_steps = [\n",
        "    \"🔑 Replace RandomEmbeddings with production embeddings (OpenAI, Sentence Transformers)\",\n",
        "    \"📚 Load real documents instead of sample data\",\n",
        "    \"⚡ Optimize vector indexing for large datasets\",\n",
        "    \"🔒 Implement proper authentication and security\",\n",
        "    \"📈 Add monitoring and performance metrics\",\n",
        "    \"🧪 Implement A/B testing for different embedding models\",\n",
        "    \"🔄 Set up automated data pipeline for document updates\",\n",
        "    \"🌐 Create REST API for vector search functionality\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(f\"\\n💡 Key Learnings:\")\n",
        "learnings = [\n",
        "    \"Vector databases enable semantic search beyond keyword matching\",\n",
        "    \"Metadata filtering adds powerful query capabilities\",\n",
        "    \"pgVector provides PostgreSQL-native vector operations\",\n",
        "    \"Random embeddings work for testing but semantic embeddings needed for production\",\n",
        "    \"Cosine distance is effective for text similarity comparisons\"\n",
        "]\n",
        "\n",
        "for learning in learnings:\n",
        "    print(f\"  • {learning}\")\n",
        "\n",
        "print(f\"\\n🔗 Useful Resources:\")\n",
        "resources = [\n",
        "    \"pgVector Documentation: https://github.com/pgvector/pgvector\", \n",
        "    \"LangChain Documentation: https://python.langchain.com/\",\n",
        "    \"OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings\",\n",
        "    \"Sentence Transformers: https://www.sbert.net/\"\n",
        "]\n",
        "\n",
        "for resource in resources:\n",
        "    print(f\"  📖 {resource}\")\n",
        "\n",
        "print(f\"\\n🎯 Thank you for exploring pgVector with LangChain!\")\n",
        "print(f\"   Feel free to experiment with different queries and embeddings!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
