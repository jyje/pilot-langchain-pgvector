{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# pgVector and LangChain Example Notebook\n",
        "\n",
        "This notebook demonstrates how to store documents in a vector database and perform similarity searches using pgVector and LangChain.\n",
        "\n",
        "## Features:\n",
        "- ğŸ”„ **Random Vector Embeddings**: No OpenAI API key required\n",
        "- ğŸ“š **Document Storage**: Store sample documents with metadata\n",
        "- ğŸ” **Similarity Search**: Find similar documents\n",
        "- ğŸ·ï¸ **Metadata Filtering**: Filter results by metadata\n",
        "- ğŸ¯ **Direct Vector Search**: Search using vector embeddings directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/jyje/Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/Codes/Profile/jyje/Repos/pilot-langchain-pgvector/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Import required libraries and existing functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "\n",
        "# Import from our existing modules\n",
        "from vector_example import RandomEmbeddings, create_sample_documents\n",
        "from config import DATABASE_URL, VECTOR_DIMENSION, COLLECTION_NAME\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain_community.vectorstores import PGVector\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ğŸ“¦ All libraries imported successfully!\")\n",
        "print(f\"ğŸ”— Database URL: {DATABASE_URL}\")\n",
        "print(f\"ğŸ“ Vector Dimension: {VECTOR_DIMENSION}\")\n",
        "print(f\"ğŸ“‚ Collection Name: {COLLECTION_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# pgVector and LangChain Example Notebook\n",
        "\n",
        "This notebook demonstrates how to store documents in a vector database and perform similarity searches using pgVector and LangChain.\n",
        "\n",
        "## Features:\n",
        "- ğŸ”„ **Random Vector Embeddings**: No OpenAI API key required\n",
        "- ğŸ“š **Document Storage**: Store sample documents with metadata  \n",
        "- ğŸ” **Similarity Search**: Find similar documents\n",
        "- ğŸ·ï¸ **Metadata Filtering**: Filter results by metadata\n",
        "- ğŸ¯ **Direct Vector Search**: Search using vector embeddings directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries and existing functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "\n",
        "# Import from our existing modules\n",
        "from vector_example import RandomEmbeddings, create_sample_documents\n",
        "from config import DATABASE_URL, VECTOR_DIMENSION, COLLECTION_NAME\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain_community.vectorstores import PGVector\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ğŸ“¦ All libraries imported successfully!\")\n",
        "print(f\"ğŸ”— Database URL: {DATABASE_URL}\")\n",
        "print(f\"ğŸ“ Vector Dimension: {VECTOR_DIMENSION}\")\n",
        "print(f\"ğŸ“‚ Collection Name: {COLLECTION_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ğŸ“š Data Generation\n",
        "\n",
        "Let's generate sample documents using the existing `create_sample_documents()` function and explore the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample documents using existing function\n",
        "sample_documents = create_sample_documents()\n",
        "\n",
        "print(f\"ğŸ“Š Generated {len(sample_documents)} sample documents\\n\")\n",
        "\n",
        "# Display the documents in a nice format\n",
        "for i, doc in enumerate(sample_documents, 1):\n",
        "    print(f\"ğŸ”¹ Document {i}:\")\n",
        "    print(f\"   Content: {doc.page_content}\")\n",
        "    print(f\"   Metadata: {doc.metadata}\")\n",
        "    print()\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "data = []\n",
        "for doc in sample_documents:\n",
        "    data.append({\n",
        "        'id': doc.metadata['id'],\n",
        "        'content': doc.page_content,\n",
        "        'category': doc.metadata['category'],\n",
        "        'source': doc.metadata['source']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"ğŸ“‹ Documents as DataFrame:\")\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. ğŸ”§ Vector Store Initialization\n",
        "\n",
        "Initialize the embedding model and pgVector store for data storage and retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize embedding model (random vectors for demonstration)\n",
        "embeddings = RandomEmbeddings(dimension=VECTOR_DIMENSION)\n",
        "print(f\"ğŸ§® Initialized RandomEmbeddings with {VECTOR_DIMENSION} dimensions\")\n",
        "\n",
        "# Test the embedding model\n",
        "test_vector = embeddings.embed_query(\"Test query\")\n",
        "print(f\"ğŸ” Sample vector shape: {len(test_vector)}\")\n",
        "print(f\"ğŸ”¢ Sample vector (first 5 elements): {test_vector[:5]}\")\n",
        "\n",
        "# Initialize PGVector store\n",
        "try:\n",
        "    vector_store = PGVector(\n",
        "        connection_string=DATABASE_URL,\n",
        "        embedding_function=embeddings,\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        distance_strategy=\"cosine\"\n",
        "    )\n",
        "    print(\"âœ… pgVector store initialized successfully!\")\n",
        "    print(f\"ğŸ“Š Using cosine distance for similarity search\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to initialize pgVector store: {e}\")\n",
        "    print(\"ğŸ”§ Make sure Docker containers are running: cd docker && docker-compose up -d\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. ğŸ’¾ Data Storage (Training Phase)\n",
        "\n",
        "Store the generated documents in the pgVector database. This is equivalent to the \"training\" phase where we build our vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store documents in the vector database\n",
        "print(\"ğŸ’¾ Storing documents in pgVector database...\")\n",
        "\n",
        "try:\n",
        "    vector_store.add_documents(sample_documents)\n",
        "    print(f\"âœ… Successfully stored {len(sample_documents)} documents!\")\n",
        "    \n",
        "    # Verify storage by checking if we can retrieve any documents\n",
        "    print(\"\\nğŸ” Verifying data storage...\")\n",
        "    \n",
        "    # Try a simple search to verify\n",
        "    test_results = vector_store.similarity_search(\"technology\", k=1)\n",
        "    if test_results:\n",
        "        print(f\"âœ… Verification successful! Found {len(test_results)} document(s)\")\n",
        "        print(f\"ğŸ“„ Sample document: {test_results[0].page_content[:50]}...\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No documents found in verification search\")\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Database now contains vector embeddings for all documents\")\n",
        "    print(f\"ğŸ”¢ Each document is represented as a {VECTOR_DIMENSION}-dimensional vector\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to store documents: {e}\")\n",
        "    print(\"ğŸ”§ Check if the database connection is working properly\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. ğŸ” Basic Similarity Search\n",
        "\n",
        "Perform similarity searches using different query texts to find the most relevant documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define search queries for testing\n",
        "search_queries = [\n",
        "    \"Tell me about artificial intelligence and machine learning\",\n",
        "    \"What are data analysis technologies?\", \n",
        "    \"Explain cloud and distributed systems\",\n",
        "    \"How does blockchain technology work?\",\n",
        "    \"What is computer vision and image processing?\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ” Performing similarity searches...\\n\")\n",
        "\n",
        "# Perform searches and display results\n",
        "for i, query in enumerate(search_queries, 1):\n",
        "    print(f\"ğŸ”¸ Search {i}: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Basic similarity search\n",
        "        similar_docs = vector_store.similarity_search(query, k=3)\n",
        "        \n",
        "        if similar_docs:\n",
        "            print(\"ğŸ“‹ Top 3 similar documents:\")\n",
        "            for j, doc in enumerate(similar_docs, 1):\n",
        "                print(f\"   {j}. {doc.page_content}\")\n",
        "                print(f\"      ğŸ“‚ Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "                print(f\"      ğŸ†” ID: {doc.metadata.get('id', 'N/A')}\")\n",
        "            \n",
        "            # Search with similarity scores\n",
        "            similar_docs_with_scores = vector_store.similarity_search_with_score(query, k=3)\n",
        "            print(\"\\nğŸ“Š Similarity scores:\")\n",
        "            for j, (doc, score) in enumerate(similar_docs_with_scores, 1):\n",
        "                print(f\"   {j}. Score: {score:.4f}\")\n",
        "        else:\n",
        "            print(\"âŒ No similar documents found\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Search failed: {e}\")\n",
        "    \n",
        "    print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. ğŸ·ï¸ Metadata Filtering Search\n",
        "\n",
        "Demonstrate how to filter search results based on metadata criteria.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metadata filtering search examples\n",
        "print(\"ğŸ·ï¸ Performing metadata filtering searches...\\n\")\n",
        "\n",
        "# Example 1: Filter by category\n",
        "try:\n",
        "    print(\"ğŸ”¹ Filter 1: Only 'technology' category documents\")\n",
        "    filtered_docs = vector_store.similarity_search(\n",
        "        query=\"Tell me about technology\",\n",
        "        k=5,\n",
        "        filter={\"category\": \"technology\"}\n",
        "    )\n",
        "    \n",
        "    if filtered_docs:\n",
        "        print(f\"ğŸ“‹ Found {len(filtered_docs)} documents in 'technology' category:\")\n",
        "        for i, doc in enumerate(filtered_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      ğŸ“‚ Category: {doc.metadata['category']}\")\n",
        "            print(f\"      ğŸ†” ID: {doc.metadata['id']}\")\n",
        "    else:\n",
        "        print(\"âŒ No documents found with specified filter\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Filtered search failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Example 2: Filter by source\n",
        "try:\n",
        "    print(\"ğŸ”¹ Filter 2: Only 'sample_data' source documents\")\n",
        "    filtered_docs = vector_store.similarity_search(\n",
        "        query=\"data processing\",\n",
        "        k=3,\n",
        "        filter={\"source\": \"sample_data\"}\n",
        "    )\n",
        "    \n",
        "    if filtered_docs:\n",
        "        print(f\"ğŸ“‹ Found {len(filtered_docs)} documents from 'sample_data' source:\")\n",
        "        for i, doc in enumerate(filtered_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      ğŸ”— Source: {doc.metadata['source']}\")\n",
        "    else:\n",
        "        print(\"âŒ No documents found with specified filter\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Filtered search failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Example 3: Search without filter for comparison\n",
        "try:\n",
        "    print(\"ğŸ”¹ Comparison: Search without any filters\")\n",
        "    all_docs = vector_store.similarity_search(\n",
        "        query=\"technology and data\",\n",
        "        k=3\n",
        "    )\n",
        "    \n",
        "    if all_docs:\n",
        "        print(f\"ğŸ“‹ Found {len(all_docs)} documents (no filter):\")\n",
        "        for i, doc in enumerate(all_docs, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "            print(f\"      ğŸ“‚ Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "            print(f\"      ğŸ”— Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"âŒ No documents found\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Search failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. ğŸ¯ Direct Vector Search\n",
        "\n",
        "Demonstrate searching using vector embeddings directly, without query text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Direct vector search examples\n",
        "print(\"ğŸ¯ Performing direct vector searches...\\n\")\n",
        "\n",
        "# Generate multiple random vectors for testing\n",
        "num_searches = 3\n",
        "for i in range(num_searches):\n",
        "    print(f\"ğŸ”¸ Vector Search {i+1}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        # Generate a random vector\n",
        "        random_vector = embeddings.embed_query(f\"random search {i+1}\")\n",
        "        \n",
        "        print(f\"ğŸ§® Generated random vector with {len(random_vector)} dimensions\")\n",
        "        print(f\"ğŸ”¢ Vector sample (first 5 elements): {random_vector[:5]}\")\n",
        "        \n",
        "        # Search using the random vector\n",
        "        similar_docs = vector_store.similarity_search_by_vector(\n",
        "            embedding=random_vector,\n",
        "            k=3\n",
        "        )\n",
        "        \n",
        "        if similar_docs:\n",
        "            print(f\"\\nğŸ“‹ Found {len(similar_docs)} similar documents:\")\n",
        "            for j, doc in enumerate(similar_docs, 1):\n",
        "                print(f\"   {j}. {doc.page_content}\")\n",
        "                print(f\"      ğŸ“‚ Category: {doc.metadata.get('category', 'N/A')}\")\n",
        "                print(f\"      ğŸ†” ID: {doc.metadata.get('id', 'N/A')}\")\n",
        "        else:\n",
        "            print(\"âŒ No similar documents found\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Vector search failed: {e}\")\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Compare vector search with text search\n",
        "print(\"ğŸ”€ Comparison: Vector vs Text Search\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    # Generate a vector for a specific query\n",
        "    query_text = \"machine learning and AI\"\n",
        "    query_vector = embeddings.embed_query(query_text)\n",
        "    \n",
        "    # Text-based search\n",
        "    text_results = vector_store.similarity_search(query_text, k=2)\n",
        "    \n",
        "    # Vector-based search using the same vector\n",
        "    vector_results = vector_store.similarity_search_by_vector(query_vector, k=2)\n",
        "    \n",
        "    print(f\"ğŸ“ Text search for: '{query_text}'\")\n",
        "    if text_results:\n",
        "        for i, doc in enumerate(text_results, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "    \n",
        "    print(f\"\\nğŸ§® Vector search using embedding of: '{query_text}'\")\n",
        "    if vector_results:\n",
        "        for i, doc in enumerate(vector_results, 1):\n",
        "            print(f\"   {i}. {doc.page_content}\")\n",
        "    \n",
        "    # Note about randomness\n",
        "    print(f\"\\nğŸ’¡ Note: Since we're using random embeddings, results may vary between runs\")\n",
        "    print(f\"   In production, you'd use consistent embeddings like OpenAI's text-embedding-ada-002\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Comparison search failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. ğŸ“Š Search Results Analysis\n",
        "\n",
        "Let's analyze and visualize the search results to better understand the vector database performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze search performance and results\n",
        "print(\"ğŸ“Š Analyzing search results and database performance...\\n\")\n",
        "\n",
        "# Collect search statistics\n",
        "search_stats = {\n",
        "    'total_documents': len(sample_documents),\n",
        "    'search_queries_tested': len(search_queries),\n",
        "    'categories': set(),\n",
        "    'sources': set(),\n",
        "    'similarity_scores': []\n",
        "}\n",
        "\n",
        "# Analyze stored documents\n",
        "for doc in sample_documents:\n",
        "    search_stats['categories'].add(doc.metadata.get('category', 'Unknown'))\n",
        "    search_stats['sources'].add(doc.metadata.get('source', 'Unknown'))\n",
        "\n",
        "# Perform a comprehensive search analysis\n",
        "comprehensive_query = \"technology data science machine learning\"\n",
        "print(f\"ğŸ” Comprehensive analysis with query: '{comprehensive_query}'\")\n",
        "\n",
        "try:\n",
        "    # Get all results with scores\n",
        "    all_results = vector_store.similarity_search_with_score(\n",
        "        comprehensive_query, \n",
        "        k=len(sample_documents)  # Get all documents\n",
        "    )\n",
        "    \n",
        "    if all_results:\n",
        "        # Extract scores for analysis\n",
        "        scores = [score for _, score in all_results]\n",
        "        search_stats['similarity_scores'] = scores\n",
        "        \n",
        "        # Create results DataFrame\n",
        "        results_data = []\n",
        "        for i, (doc, score) in enumerate(all_results, 1):\n",
        "            results_data.append({\n",
        "                'rank': i,\n",
        "                'content': doc.page_content[:50] + \"...\",\n",
        "                'category': doc.metadata.get('category', 'N/A'),\n",
        "                'source': doc.metadata.get('source', 'N/A'),\n",
        "                'similarity_score': round(score, 4),\n",
        "                'document_id': doc.metadata.get('id', 'N/A')\n",
        "            })\n",
        "        \n",
        "        results_df = pd.DataFrame(results_data)\n",
        "        print(\"\\nğŸ“‹ Complete Search Results:\")\n",
        "        display(results_df)\n",
        "        \n",
        "        # Statistics summary\n",
        "        print(f\"\\nğŸ“ˆ Search Statistics Summary:\")\n",
        "        print(f\"   ğŸ“š Total documents in database: {search_stats['total_documents']}\")\n",
        "        print(f\"   ğŸ” Search queries tested: {search_stats['search_queries_tested']}\")\n",
        "        print(f\"   ğŸ“‚ Categories found: {', '.join(search_stats['categories'])}\")\n",
        "        print(f\"   ğŸ”— Sources found: {', '.join(search_stats['sources'])}\")\n",
        "        print(f\"   ğŸ“Š Similarity score range: {min(scores):.4f} - {max(scores):.4f}\")\n",
        "        print(f\"   ğŸ“Š Average similarity score: {np.mean(scores):.4f}\")\n",
        "        print(f\"   ğŸ“Š Similarity score std dev: {np.std(scores):.4f}\")\n",
        "        \n",
        "        # Top and bottom results\n",
        "        print(f\"\\nğŸ† Most similar document:\")\n",
        "        print(f\"   Content: {all_results[0][0].page_content}\")\n",
        "        print(f\"   Score: {all_results[0][1]:.4f}\")\n",
        "        \n",
        "        print(f\"\\nğŸ”» Least similar document:\")\n",
        "        print(f\"   Content: {all_results[-1][0].page_content}\")\n",
        "        print(f\"   Score: {all_results[-1][1]:.4f}\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ No results found for comprehensive analysis\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Analysis failed: {e}\")\n",
        "\n",
        "# Performance note\n",
        "print(f\"\\nğŸ’¡ Performance Notes:\")\n",
        "print(f\"   ğŸ”„ Random embeddings provide consistent vector operations\")\n",
        "print(f\"   âš¡ Search speed depends on database size and indexing\")\n",
        "print(f\"   ğŸ¯ In production, use semantic embeddings (OpenAI, Sentence Transformers, etc.)\")\n",
        "print(f\"   ğŸ“ˆ Vector similarity scores closer to 0 indicate higher similarity (cosine distance)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. ğŸ‰ Summary and Next Steps\n",
        "\n",
        "This notebook demonstrated the complete workflow of using pgVector with LangChain for vector-based document storage and retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of what we accomplished\n",
        "print(\"ğŸ‰ Notebook Execution Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "summary_points = [\n",
        "    \"âœ… Successfully imported functions from vector_example.py\",\n",
        "    \"âœ… Generated sample documents with metadata\",\n",
        "    \"âœ… Initialized RandomEmbeddings (no OpenAI API required)\",\n",
        "    \"âœ… Connected to pgVector database\",\n",
        "    \"âœ… Stored documents in vector database (training phase)\",\n",
        "    \"âœ… Performed similarity searches with various queries\",\n",
        "    \"âœ… Demonstrated metadata filtering capabilities\",\n",
        "    \"âœ… Executed direct vector searches\",\n",
        "    \"âœ… Analyzed search results and performance statistics\"\n",
        "]\n",
        "\n",
        "for point in summary_points:\n",
        "    print(f\"  {point}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Final Statistics:\")\n",
        "print(f\"  ğŸ“š Documents stored: {len(sample_documents)}\")\n",
        "print(f\"  ğŸ” Search methods tested: Text search, Filtered search, Vector search\")\n",
        "print(f\"  ğŸ“ Vector dimensions: {VECTOR_DIMENSION}\")\n",
        "print(f\"  ğŸ¯ Distance metric: Cosine similarity\")\n",
        "\n",
        "print(f\"\\nğŸš€ Next Steps for Production:\")\n",
        "next_steps = [\n",
        "    \"ğŸ”‘ Replace RandomEmbeddings with production embeddings (OpenAI, Sentence Transformers)\",\n",
        "    \"ğŸ“š Load real documents instead of sample data\",\n",
        "    \"âš¡ Optimize vector indexing for large datasets\",\n",
        "    \"ğŸ”’ Implement proper authentication and security\",\n",
        "    \"ğŸ“ˆ Add monitoring and performance metrics\",\n",
        "    \"ğŸ§ª Implement A/B testing for different embedding models\",\n",
        "    \"ğŸ”„ Set up automated data pipeline for document updates\",\n",
        "    \"ğŸŒ Create REST API for vector search functionality\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ Key Learnings:\")\n",
        "learnings = [\n",
        "    \"Vector databases enable semantic search beyond keyword matching\",\n",
        "    \"Metadata filtering adds powerful query capabilities\",\n",
        "    \"pgVector provides PostgreSQL-native vector operations\",\n",
        "    \"Random embeddings work for testing but semantic embeddings needed for production\",\n",
        "    \"Cosine distance is effective for text similarity comparisons\"\n",
        "]\n",
        "\n",
        "for learning in learnings:\n",
        "    print(f\"  â€¢ {learning}\")\n",
        "\n",
        "print(f\"\\nğŸ”— Useful Resources:\")\n",
        "resources = [\n",
        "    \"pgVector Documentation: https://github.com/pgvector/pgvector\", \n",
        "    \"LangChain Documentation: https://python.langchain.com/\",\n",
        "    \"OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings\",\n",
        "    \"Sentence Transformers: https://www.sbert.net/\"\n",
        "]\n",
        "\n",
        "for resource in resources:\n",
        "    print(f\"  ğŸ“– {resource}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Thank you for exploring pgVector with LangChain!\")\n",
        "print(f\"   Feel free to experiment with different queries and embeddings!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
